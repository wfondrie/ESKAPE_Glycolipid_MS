---
title: "Dot Product Comparison of Lipid A"
author: "Will Fondrie"
date: "August 12, 2015"
output: html_document
---

### Loading Libraries  
First, we need to load the libraries that we will use to working with the MALDI-TOF spectra. There is a handy
package on CRAN called "[MALDIquant](http://strimmerlab.org/software/maldiquant/)" that is build exactly for this. With it and its import package, 
"MALDIquantForeign" we can process the mzXML MS data. Below is the code for loading the packages:

```{r, message=F}
library(MALDIquant)
library(MALDIquantForeign)
library(rafalib)
```

### Loading the MS data
Now its time to import the mass spectra. The first command retrieves a list of all the mzXML files in our "data" folder. The second line then reads them all into a "MassSpectrum" object (part of the MALDIquant
package)  


```{r, message=F}
file.list <- list.files("data/", pattern=".mzXML$")
spectra <- importMzXml(paste0("data/",file.list))

# Plots the spectra
mypar(4,4)
invisible(lapply(spectra,plot,xlim=c(400,2000)))

```

### Preprocessing the MS spectra
The spectra are first variance stabilized using the square root transformation (line 1 below). Then the spectra are smoothed using the Savitzky-Golay-Filter (line2) . The "halfWindowSize" arguement should be smaller the the FWHM of peaks in our spectra. 

```{r}
spectra <- transformIntensity(spectra, method="sqrt")
spectra <- smoothIntensity(spectra, method="SavitzkyGolay", halfWindowSize=5)

# Plots the spectra
mypar(4,4)
invisible(lapply(spectra,plot,xlim=c(400,2000)))
```

Following this, baseline correction was performed using the SNIP algorithm. The number of iterations for this were chosen to minimise peakloss. To determine this, we plot the baseline estimation at various iterations. in a couple spectra. Below is one example (this code was adapted from the "Species Identification using MALDIquant" vignette). 

```{r}

mypar()
## define iteration steps: 25, 50, ..., 100
iterations <- seq(from=25, to=100, by=25)
## define different colors for each step
col <- rainbow(length(iterations))
plot(spectra[[1]])
## draw different baseline estimates
for (i in seq(along=iterations)) {
  baseline <- estimateBaseline(spectra[[1]], method="SNIP",
                               iterations=iterations[i])
  lines(baseline, col=col[i], lwd=2)
}
legend("topright", legend=iterations, col=col, lwd=1)

# plots all of the spectra with 60 iterations
mypar(4,4)
invisible(lapply(spectra, function(x) {
  baseline <- estimateBaseline(x, method="SNIP",iterations=60)
  plot(x, xlim=c(400,2000))
  lines(baseline,col="red",lwd=2)
}))
```

And to actually remove the baseline, with 60 iterations being chosen after seeing the above plot:

```{R}
spectra <- removeBaseline(spectra, method="SNIP", iterations=60)

# Plots the spectra
mypar(4,4)
invisible(lapply(spectra,plot,xlim=c(400,2000)))
```

Now we can calibrate the intensities accross all spectra using the total ion current (TIC) (line 1 below). Also, we can recalibrate our masses accross all spectra as well (line 2 below).

```{R}
spectra <- calibrateIntensity(spectra,method="TIC")
spectra <- alignSpectra(spectra)

# Plots the spectra
mypar(4,4)
invisible(lapply(spectra,plot,xlim=c(400,2000)))
```  

#### Peak Picking

For peak picking, we need to select a S/N threshhold that will balance our sensitivity and specificity. First, we need to estimate the noise in the spectra and visualize where certain S/N cutoffs will be. In the code below, we use the SuperSmoother algorithm [(Friedman, 1984)](http://www.slac.stanford.edu/cgi-wrap/getdoc/slac-pub-3477.pdf) to estimate the noise and visualize various S/N values.

```{R}
mypar()

## define snrs steps: 1, 1.5, ... 2.5
snrs <- seq(from=1, to=2.5, by=0.5)
## define different colors for each step
col <- rainbow(length(snrs))
## estimate noise
noise <- estimateNoise(spectra[[1]],
                       method="SuperSmoother")
plot(spectra[[1]])
for (i in seq(along=snrs)) {
  lines(noise[, "mass"],
        noise[, "intensity"]*snrs[i],
        col=col[i], lwd=2)
}
legend("topright", legend=snrs, col=col, lwd=1)


# plots all of the spectra with 2.5 S/N
mypar(4,4)
SNR <- 2.5
invisible(lapply(spectra, function(x) {
  noise <- estimateNoise(x, method="SuperSmoother")
  plot(x, xlim=c(400,2000))
  lines(noise[,"mass"],noise[,"intensity"]*SNR, col= "red", lwd=2)
}))

```

Based on this, we chose the conservative S/N of 2.5 and binned to combine peaks within 0.002 m/z accross spectra.

```{R}
peaks <- detectPeaks(spectra, SNR=2.5, halfWindowSize=5, method="SuperSmoother")
peaks <- binPeaks(peaks, tolerance=0.002)

# Plots the spectra
mypar(4,4)
for (i in 1:length(spectra)) {
  plot(spectra[[i]], xlim=c(400,2000))
  points(peaks[[i]], col="red", pch=4)
}

invisible(lapply(peaks,plot, xlim=c(400,2000)))
```

### Aggregating the features

The peaks detected from each spectra were then combined into a matrix containing the features of all the spectra. This is what will be used when we calculate the dot product comparison. In order to name the spectra appropriately, the sample name was parsed out of the file name.

```{R}
sample <- sapply(spectra, function(x) metaData(x)$file)
sample <- gsub(".*\\\\", "", sample)
sample <- gsub(".mzXML$","",sample)
sample <- factor(sample)

features <- intensityMatrix(peaks, spectra)
rownames(features) <- sample
```

### Visualizing a difference

Just to check how things were going, I did a quick heirarchical clustering of the spectra to look at how different they are. To do this, I used the pvclust package.

```{R}
library("pvclust")

opar <- par()
par(cex=0.75, pin = c(6,10), mai=c(1,1,0.5,0.5))
pv <- pvclust(t(features), method.hclust = "ward.D2",
              method.dist = "euclidean")
plot(pv, print.num=F)
```

### Calculating the Dot Product

The code below calculates the dot product for each spectra aligned with every other one. The bins used are the bins calculated during the peak alignment step with 0.002 m/z tolerance. Each sample is represented and as a normalized unit vector, such that our final dot product is scaled between 0 and 1. Finally, this is plotted as a heatmap.

```{r,fig.width=8, fig.height=8}
library("plyr")
library("reshape2")
library("ggplot2")
library("scales")

normFeatures <- aaply(features,1,function(x) x/sqrt(x %*% x))

dot <- normFeatures %*% t(normFeatures)

df <- as.data.frame(dot)
df$names <- row.names(df)

dfMelt <- melt(df)

p <- ggplot(dfMelt, aes(variable,names)) + geom_tile(aes(fill=value)) +
  scale_fill_continuous(low=("black"), high="red") +
  theme(axis.text.x = element_text(angle=90, hjust=1)) + 
  coord_fixed(ratio = 1)
p
ggsave("heatmap.png",width=10,height=10,units="in")
```